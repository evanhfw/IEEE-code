{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install and import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T03:26:52.445506Z",
     "iopub.status.busy": "2025-09-05T03:26:52.445227Z",
     "iopub.status.idle": "2025-09-05T03:27:01.719293Z",
     "shell.execute_reply": "2025-09-05T03:27:01.718227Z",
     "shell.execute_reply.started": "2025-09-05T03:26:52.445485Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.5/35.5 MB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0mm\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.7/145.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install sktime pandas numpy xgboost -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T03:27:01.721452Z",
     "iopub.status.busy": "2025-09-05T03:27:01.721090Z",
     "iopub.status.idle": "2025-09-05T03:27:05.731679Z",
     "shell.execute_reply": "2025-09-05T03:27:05.730846Z",
     "shell.execute_reply.started": "2025-09-05T03:27:01.721414Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sktime.forecasting.base import ForecastingHorizon\n",
    "from sktime.forecasting.compose import DirectTabularRegressionForecaster, DirRecTabularRegressionForecaster, MultioutputTabularRegressionForecaster, RecursiveTabularRegressionForecaster\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T03:27:05.733280Z",
     "iopub.status.busy": "2025-09-05T03:27:05.732697Z",
     "iopub.status.idle": "2025-09-05T03:27:07.602907Z",
     "shell.execute_reply": "2025-09-05T03:27:07.601715Z",
     "shell.execute_reply.started": "2025-09-05T03:27:05.733245Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel('/kaggle/input/listrik-malay/data.xlsx', parse_dates=['time'], index_col='time').drop(columns=['No']).iloc[:-1].asfreq('h')\n",
    "data.columns = ['consumption']\n",
    "data = data.ffill()\n",
    "data.columns = ['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create exogeneous data (calendar features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T03:27:12.907400Z",
     "iopub.status.busy": "2025-09-05T03:27:12.905933Z",
     "iopub.status.idle": "2025-09-05T03:27:12.923295Z",
     "shell.execute_reply": "2025-09-05T03:27:12.922019Z",
     "shell.execute_reply.started": "2025-09-05T03:27:12.907349Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data['year'] = data.index.year\n",
    "data['month'] = data.index.month\n",
    "data['dayofyear'] = data.index.dayofyear\n",
    "data['dayofmonth'] = data.index.day\n",
    "data['dayofweek'] = data.index.dayofweek\n",
    "data['hour'] = data.index.hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test data and cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T03:27:26.297630Z",
     "iopub.status.busy": "2025-09-05T03:27:26.296718Z",
     "iopub.status.idle": "2025-09-05T03:27:26.310662Z",
     "shell.execute_reply": "2025-09-05T03:27:26.309734Z",
     "shell.execute_reply.started": "2025-09-05T03:27:26.297598Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16775 24 16775 24\n"
     ]
    }
   ],
   "source": [
    "X = data.drop(columns=['y'])\n",
    "y = data['y']\n",
    "\n",
    "RANGE_FOLD = 25\n",
    "\n",
    "fold = []\n",
    "\n",
    "for i in range(RANGE_FOLD):\n",
    "    fold.append((X.iloc[i*24:16775+i*24], X.iloc[16775+i*24:16775+i*24+24], y.iloc[i*24:16775+i*24], y.iloc[16775+i*24:16775+i*24+24]))\n",
    "\n",
    "X_train, X_test, y_train, y_test = fold[0]\n",
    "\n",
    "print(len(X_train), len(X_test), len(y_train), len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model training and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-05T03:29:58.175998Z",
     "iopub.status.busy": "2025-09-05T03:29:58.175622Z",
     "iopub.status.idle": "2025-09-05T03:29:58.182260Z",
     "shell.execute_reply": "2025-09-05T03:29:58.181339Z",
     "shell.execute_reply.started": "2025-09-05T03:29:58.175951Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBRegressor(random_state=42)\n",
    "fh = ForecastingHorizon(np.arange(1, len(y_test) + 1))\n",
    "\n",
    "\n",
    "direct = DirectTabularRegressionForecaster(model, window_length=7*3*24)\n",
    "dirrec = DirRecTabularRegressionForecaster(model, window_length=7*3*24)\n",
    "multi = MultioutputTabularRegressionForecaster(model, window_length=7*3*24)\n",
    "recursive = RecursiveTabularRegressionForecaster(model, window_length=7*3*24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def model_predict(\n",
    "    model: DirectTabularRegressionForecaster\n",
    "    | DirRecTabularRegressionForecaster\n",
    "    | MultioutputTabularRegressionForecaster\n",
    "    | RecursiveTabularRegressionForecaster,\n",
    "    fold: list[tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]],\n",
    "    fh: ForecastingHorizon,\n",
    "    name: str,\n",
    "    exogeneous: bool,\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform time series forecasting using cross-validation with different sktime forecaster types.\n",
    "\n",
    "    This function trains and evaluates forecasting models using time series cross-validation.\n",
    "    It supports both exogenous and non-exogenous forecasting approaches and automatically\n",
    "    saves predictions and error metrics to CSV files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    model : DirectTabularRegressionForecaster | DirRecTabularRegressionForecaster | MultioutputTabularRegressionForecaster | RecursiveTabularRegressionForecaster\n",
    "        The forecasting model to use. Must be one of the supported sktime tabular regression forecasters:\n",
    "        - DirectTabularRegressionForecaster: Direct forecasting strategy\n",
    "        - DirRecTabularRegressionForecaster: Direct-Recursive hybrid strategy\n",
    "        - MultioutputTabularRegressionForecaster: Multi-output forecasting strategy\n",
    "        - RecursiveTabularRegressionForecaster: Recursive forecasting strategy\n",
    "\n",
    "    fold : list[tuple[pd.DataFrame, pd.DataFrame, pd.Series, pd.Series]]\n",
    "        List of cross-validation folds. Each fold is a tuple containing:\n",
    "        - X_train: Training exogenous features (pd.DataFrame)\n",
    "        - X_test: Test exogenous features (pd.DataFrame)\n",
    "        - y_train: Training target values (pd.Series)\n",
    "        - y_test: Test target values (pd.Series)\n",
    "\n",
    "    fh : ForecastingHorizon\n",
    "        The forecasting horizon object from sktime that defines how many steps ahead to forecast.\n",
    "        This determines the length of predictions made by the model.\n",
    "\n",
    "    name : str\n",
    "        Name identifier for the model. Used in output filenames and progress messages.\n",
    "        Should be descriptive (e.g., \"XGBoost_Direct\", \"XGBoost_Recursive\").\n",
    "\n",
    "    exogeneous : bool\n",
    "        Whether to use exogenous features in forecasting:\n",
    "        - True: Use exogenous features (X_train, X_test) for training and prediction\n",
    "        - False: Use only target variable (y_train) for univariate forecasting\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        This function does not return values. Instead, it saves results to CSV files in the 'predictions' directory.\n",
    "\n",
    "    Side Effects\n",
    "    ------------\n",
    "    - Creates a 'predictions' directory if it doesn't exist\n",
    "    - Saves prediction results to CSV files:\n",
    "        - For exogenous models: '{name}_predictions_exo.csv' and '{name}_mape_exo.csv'\n",
    "        - For non-exogenous models: '{name}_predictions.csv' and '{name}_mape.csv'\n",
    "    - Prints progress messages for each fold being processed\n",
    "\n",
    "    Files Created\n",
    "    -------------\n",
    "    predictions/{name}_predictions.csv or predictions/{name}_predictions_exo.csv\n",
    "        Contains predictions for each fold in separate columns (Fold 1, Fold 2, etc.)\n",
    "\n",
    "    predictions/{name}_mape.csv or predictions/{name}_mape_exo.csv\n",
    "        Contains Mean Absolute Percentage Error (MAPE) for each fold in separate columns\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - The function uses MAPE (Mean Absolute Percentage Error) as the evaluation metric\n",
    "    - MAPE is calculated as: |actual - predicted| / actual * 100\n",
    "    - Each fold's results are stored in separate columns of the output DataFrames\n",
    "    - The function handles both exogenous and non-exogenous forecasting scenarios\n",
    "    - Progress is printed for each fold being processed\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> from sktime.forecasting.compose import DirectTabularRegressionForecaster\n",
    "    >>> from sktime.forecasting.base import ForecastingHorizon\n",
    "    >>> import xgboost as xgb\n",
    "    >>>\n",
    "    >>> # Create model and forecasting horizon\n",
    "    >>> model = DirectTabularRegressionForecaster(xgb.XGBRegressor(), window_length=504)\n",
    "    >>> fh = ForecastingHorizon([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24])\n",
    "    >>>\n",
    "    >>> # Run predictions with exogenous features\n",
    "    >>> model_predict(model, fold, fh, \"XGBoost_Direct\", exogeneous=True)\n",
    "\n",
    "    >>> # Run predictions without exogenous features\n",
    "    >>> model_predict(model, fold, fh, \"XGBoost_Direct\", exogeneous=False)\n",
    "    \"\"\"\n",
    "    predictions_df = pd.DataFrame()\n",
    "    predictions_df_exo = pd.DataFrame()\n",
    "    test_df = pd.DataFrame()\n",
    "\n",
    "    for i, (X_train, X_test, y_train, y_test) in enumerate(fold):\n",
    "        print(f\"Processing fold {i + 1} - {name}\")\n",
    "\n",
    "        # Create predictions directory if it doesn't exist\n",
    "        if not os.path.exists(\"predictions\"):\n",
    "            os.makedirs(\"predictions\")\n",
    "            print(\"Created 'predictions' directory\")\n",
    "\n",
    "        if exogeneous:\n",
    "            model.fit(y_train, X=X_train, fh=fh)\n",
    "            predictions_df_exo[f\"Fold {i + 1}\"] = model.predict(fh, X=X_test).values\n",
    "\n",
    "            test_df[f\"Fold {i + 1}\"] = y_test.values\n",
    "\n",
    "            mape_df_exo = np.abs(test_df - predictions_df_exo) / test_df * 100\n",
    "\n",
    "            predictions_df_exo.to_csv(f\"predictions/{name}_predictions_exo.csv\")\n",
    "            mape_df_exo.to_csv(f\"predictions/{name}_mape_exo.csv\")\n",
    "\n",
    "        else:\n",
    "            # Time non-exogenous predictions\n",
    "            model.fit(y_train, fh=fh)\n",
    "            predictions_df[f\"Fold {i + 1}\"] = model.predict(fh).values\n",
    "\n",
    "            mape_df = np.abs(test_df - predictions_df) / test_df * 100\n",
    "            predictions_df.to_csv(f\"predictions/{name}_predictions.csv\")\n",
    "            mape_df.to_csv(f\"predictions/{name}_mape.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=== FORECASTING MODEL EXAMPLES ===\\n\")\n",
    "\n",
    "# 1. Direct Tabular Regression Forecaster\n",
    "print(\"1. Direct Tabular Regression Forecaster\")\n",
    "print(\"   - Strategy: Direct forecasting (separate model for each horizon step)\")\n",
    "print(\"   - Use case: When you want independent models for each prediction step\")\n",
    "print(\"   - Pros: No error propagation, parallel training possible\")\n",
    "print(\n",
    "    \"   - Cons: More models to train, doesn't capture temporal dependencies between steps\\n\"\n",
    ")\n",
    "\n",
    "# Example with exogenous features\n",
    "print(\"Running Direct model with exogenous features...\")\n",
    "model_predict(direct, fold, fh, \"XGBoost_Direct_Exo\", exogeneous=True)\n",
    "\n",
    "# Example without exogenous features\n",
    "print(\"Running Direct model without exogenous features...\")\n",
    "model_predict(direct, fold, fh, \"XGBoost_Direct_NoExo\", exogeneous=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n",
    "# 2. DirRec Tabular Regression Forecaster\n",
    "print(\"2. DirRec Tabular Regression Forecaster\")\n",
    "print(\"   - Strategy: Direct-Recursive hybrid (combines both approaches)\")\n",
    "print(\"   - Use case: When you want benefits of both direct and recursive methods\")\n",
    "print(\"   - Pros: Balances accuracy and computational efficiency\")\n",
    "print(\"   - Cons: More complex than pure direct or recursive\\n\")\n",
    "\n",
    "# Example with exogenous features\n",
    "print(\"Running DirRec model with exogenous features...\")\n",
    "model_predict(dirrec, fold, fh, \"XGBoost_DirRec_Exo\", exogeneous=True)\n",
    "\n",
    "# Example without exogenous features\n",
    "print(\"Running DirRec model without exogenous features...\")\n",
    "model_predict(dirrec, fold, fh, \"XGBoost_DirRec_NoExo\", exogeneous=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n",
    "# 3. Recursive Tabular Regression Forecaster\n",
    "print(\"3. Recursive Tabular Regression Forecaster\")\n",
    "print(\"   - Strategy: Recursive forecasting (uses previous predictions as input)\")\n",
    "print(\"   - Use case: When temporal dependencies are important\")\n",
    "print(\"   - Pros: Captures temporal patterns, single model\")\n",
    "print(\"   - Cons: Error propagation, sequential prediction\\n\")\n",
    "\n",
    "# Example with exogenous features\n",
    "print(\"Running Recursive model with exogenous features...\")\n",
    "model_predict(recursive, fold, fh, \"XGBoost_Recursive_Exo\", exogeneous=True)\n",
    "\n",
    "# Example without exogenous features\n",
    "print(\"Running Recursive model without exogenous features...\")\n",
    "model_predict(recursive, fold, fh, \"XGBoost_Recursive_NoExo\", exogeneous=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50 + \"\\n\")\n",
    "\n",
    "# 4. Multioutput Tabular Regression Forecaster\n",
    "print(\"4. Multioutput Tabular Regression Forecaster\")\n",
    "print(\"   - Strategy: Multi-output regression (single model predicts all steps)\")\n",
    "print(\"   - Use case: When you want to predict all horizon steps simultaneously\")\n",
    "print(\"   - Pros: Single model, captures dependencies between steps\")\n",
    "print(\"   - Cons: Requires multi-output capable base model\\n\")\n",
    "\n",
    "# Example with exogenous features\n",
    "print(\"Running Multioutput model with exogenous features...\")\n",
    "model_predict(multi, fold, fh, \"XGBoost_Multioutput_Exo\", exogeneous=True)\n",
    "\n",
    "# Example without exogenous features\n",
    "print(\"Running Multioutput model without exogenous features...\")\n",
    "model_predict(multi, fold, fh, \"XGBoost_Multioutput_NoExo\", exogeneous=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"All model examples completed!\")\n",
    "print(\"Check the 'predictions' directory for results.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train the simple XGBoost model\n",
    "print(\"Training simple XGBoost model...\")\n",
    "simple_model = xgb.XGBRegressor(random_state=42)\n",
    "\n",
    "# Simple fit - just X_train and y_train (no forecasting horizon, no lagged values)\n",
    "simple_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "print(\"Making predictions...\")\n",
    "predictions = simple_model.predict(X_test)\n",
    "\n",
    "# Calculate metrics\n",
    "mape = np.abs(y_test - predictions) / y_test * 100\n",
    "mae = np.abs(y_test - predictions).mean()\n",
    "rmse = np.sqrt(((y_test - predictions) ** 2).mean())\n",
    "\n",
    "print(f\"\\n=== RESULTS ===\")\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "print(f\"Root Mean Square Error (RMSE): {rmse:.4f}\")\n",
    "print(f\"Mean Absolute Percentage Error (MAPE): {mape.mean():.4f}%\")\n",
    "print(f\"MAPE Range: {mape.min():.4f}% - {mape.max():.4f}%\")\n",
    "\n",
    "# Create results DataFrame\n",
    "results_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Actual\": y_test.values,\n",
    "        \"Predicted\": predictions,\n",
    "        \"Error\": y_test.values - predictions,\n",
    "        \"MAPE\": mape.values,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"\\n=== SAMPLE PREDICTIONS ===\")\n",
    "print(results_df.head(10))\n",
    "\n",
    "# Save results\n",
    "if not os.path.exists(\"predictions\"):\n",
    "    os.makedirs(\"predictions\")\n",
    "\n",
    "results_df.to_csv(\"predictions/simple_xgboost_results.csv\")\n",
    "print(f\"\\nResults saved to: predictions/simple_xgboost_results.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6369174,
     "sourceId": 10291336,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
